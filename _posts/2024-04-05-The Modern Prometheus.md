# The Modern Prometheus: Recalling the Foundations of Deep Learning with fast.ai

## Overview
In this post, I will cover what I learnt from the first three sections of *Practical Deep Learning* by fast.ai:
* Lesson 1: Getting Started.
* Lesson 2: Deployment.
* Lesson 3: Neural Net Foundations.

One interesting piece of information to note about the course is that it refers to a textbook titled *Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD* by Jeremy Howard and Sylvain Gugger. In the coming weeks, this may be a good resource to refer to.

## Learning Outcomes
One of the main learning outcomes of these first few sections of the course was consolidating my ability to set up simple Deep Learning environments. Google Colab and Windows Subsystem for Linux are both services I am familiar with, but also utilising Hugging Face Space for web deployment was a wonderful educational experience.

In section 3 of the course, stochastic gradient descent and rectified linear functions are covered in great detail. Although these are topics I have explored in the past, it was interesting to see how they were covered in this course. The practical emphasis (in building a regression model and discussing issues of implementation) was a wonderful component of this lesson.
